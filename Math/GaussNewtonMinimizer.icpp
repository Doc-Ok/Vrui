/***********************************************************************
GaussNewtonMinimizer - Generic class to minimize a set of equations in a
least-squares sense using the Gauss-Newton algorithm, templatized by a
kernel class implementing a specific optimization problem.
Copyright (c) 2018 Oliver Kreylos

This file is part of the Templatized Math Library (Math).

The Templatized Math Library is free software; you can redistribute it
and/or modify it under the terms of the GNU General Public License as
published by the Free Software Foundation; either version 2 of the
License, or (at your option) any later version.

The Templatized Math Library is distributed in the hope that it will be
useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
General Public License for more details.

You should have received a copy of the GNU General Public License along
with the Templatized Math Library; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
***********************************************************************/

#define MATH_GAUSSNEWTONMINIMIZER_IMPLEMENTATION

#include <Math/GaussNewtonMinimizer.h>

#include <Math/Math.h>
#include <Math/Matrix.h>

namespace Math {

/*************************************
Methods of class GaussNewtonMinimizer:
*************************************/

template <class KernelParam>
inline
typename GaussNewtonMinimizer<KernelParam>::Scalar
GaussNewtonMinimizer<KernelParam>::minimize(
	typename GaussNewtonMinimizer<KernelParam>::Kernel& kernel)
	{
	/* Create the least-squares Jacobian and residual matrices: */
	Matrix jtj(numVariables,numVariables);
	Matrix jtr(numVariables,1);
	
	Scalar residual2;
	size_t nextProgressCallIteration=progressFrequency;
	for(size_t iteration=0;iteration<maxNumIterations;++iteration)
		{
		/* Reset the least-squares matrices and residual: */
		for(unsigned int i=0;i<numVariables;++i)
			{
			for(unsigned int j=0;j<numVariables;++j)
				jtj(i,j)=0.0;
			jtr(i)=0.0;
			}
		residual2=Scalar(0);
		
		/* Accumulate all function batches in the optimization kernel into the least-squares matrices and residual: */
		Scalar derivatives[numFunctionsInBatch][numVariables];
		Scalar values[numFunctionsInBatch];
		for(unsigned int batch=0;batch<kernel.getNumBatches();++batch)
			{
			/* Evaluate the optimization kernel's values and derivatives for this function batch: */
			kernel.calcValueBatch(batch,values);
			kernel.calcDerivativeBatch(batch,derivatives);
			
			/* Accumulate all functions in the batch into the least-squares matrices: */
			for(unsigned int function=0;function<numFunctionsInBatch;++function)
				{
				/* Enter the function's derivative into the least-squares Jacobian matrix: */
				for(unsigned int i=0;i<numVariables;++i)
					for(unsigned int j=0;j<numVariables;++j)
						jtj(i,j)+=derivatives[function][i]*derivatives[function][j];
				
				/* Enter the function's value into the least-squares residual matrix: */
				for(unsigned int i=0;i<numVariables;++i)
					jtr(i)+=derivatives[function][i]*values[function];
				
				/* Accumulate the function's residual: */
				residual2+=sqr(values[function]);
				}
			}
		
		try
			{
			/* Calculate the Gauss-Newton step vector: */
			Matrix step=jtr.divideFullPivot(jtj);
			Scalar stepVector[numVariables];
			for(unsigned int i=0;i<numVariables;++i)
				stepVector[i]=Scalar(step(i));
			
			/* Update the kernel's state: */
			kernel.negStep(stepVector);
			
			/* Check if it's time to call the progress callback: */
			if(progressCallback!=0&&iteration+1==nextProgressCallIteration)
				{
				/* Call the progress callback: */
				ProgressCallbackData cbData(kernel,residual2,false);
				(*progressCallback)(cbData);
				
				/* Advance the progress callback counter: */
				nextProgressCallIteration+=progressFrequency;
				}
			}
		catch(const Matrix::Error&)
			{
			/* Bail out: */
			break;
			}
		}
	
	if(progressCallback!=0)
		{
		/* Call the progress callback with the final optimization result: */
		ProgressCallbackData cbData(kernel,residual2,true);
		(*progressCallback)(cbData);
		}
	
	/* Return the final residual: */
	return residual2;
	}

}
